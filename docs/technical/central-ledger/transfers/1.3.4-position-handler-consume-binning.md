# Position Handler Consume (Batch / Bin support)

Sequence design diagram for Position Handler Consume process.


## Overview
![Transfers-Position-Binning.drawio.svg](../assets/diagrams/architecture/Transfers-Position-Binning.drawio.svg)

### Algorithm

This algorithm manages message batching, processing, and auditing through binning, utilizing MySQL transactions and supporting various transfer actions in a highly efficient manner.

1. **Handler:**

    - **Binning:**
        - The initial batch size is determined by the `batchSize` configuration.
        - The messages consumed from Kafka are stored in memory.
        - Messages are assigned to bins based on the impacted position `account ID` (Prepare: Payer Position Account, Fulfil: Payee Position Account), and sub-bins are created based on the `action`.
        - Each message is audited as it's assigned to a bin.
        - Note: Messages in bins are references to the message content in memory, avoiding duplication.
    
    - **Processing:**
        - Begin a transaction (TX) on MySQL.
        - For each bin:
            - Call the Bin Processor with the bin and TX.
            - After getting result, send and audit notifications based on the transfers result list from the Batch Processor.
        - Commit the offset.
        - End the TX (Commit TX to MySQL). Rollback is reserved for complete infrastructure failure only.

3. **Bin Processor:**
   - Input: Accepts a bin and TX for processing.
   - Output: Provides a list of transfers in either a reserved or aborted state.
   - Processing Order:
     - Fulfil
     - Aborts and Timeouts
     - Prepare
   - The Bin Processor calls the domain functions for above actions by passing the batch of messages.
   - After getting result for each function call it accumulates the available position, position changes, transfer state changes and a list of notification messages to be sent
   - Return the accumulated data to the handler for further processing

4. Additionally, the system supports single message processing as well.


### Questions

- **Message Replay Prevention:** How do we ensure that we do not replay messages?

### Issues

- **Locking Issue:** The above high-level algorithm might suffer from long "locks" on the position table when Kafka messages are not pre-partitioned correctly by the position account ID. This issue applies when processing mixed messages or when the number of partitions exceeds consumers.

### Mitigation

- Ensure a sufficient number of consumers, ideally more than partitions.
- Have enough partitions to ensure unique binning (no message key hash conflicts).
- Use the correct message key when producing position events by the position account ID and the scenario (Prepare: Payer Position Account, Fulfil: Payee Position Account).

### Future Enhancements

- **Enhanced Auditing:** Support batch events auditing (e.g., audits for ingress/egress, etc).
- Messages in each bin can be sorted from smallest to largest amount.

## Sequence Diagrams
### Message Consumption and Binning
![seq-position-1.3.4.1-binning.svg](../assets/diagrams/sequence/seq-position-1.3.4.1-binning.svg)

### Position-Fulfil Domain
![seq-position-1.3.4.2-fulfil-v1.1-domain.svg](../assets/diagrams/sequence/seq-position-1.3.4.2-fulfil-v1.1-domain.svg)

### Position-Abort Domain
![seq-position-1.3.4.3-abort-domain.svg](../assets/diagrams/sequence/seq-position-1.3.4.3-abort-domain.svg)

### Position-Timeout Domain
![seq-position-1.3.4.4-timeout-reserved-domain.svg](../assets/diagrams/sequence/seq-position-1.3.4.4-timeout-reserved-domain.svg)

### Position-Prepare Domain
![seq-position-1.3.4.5-prepare-domain.svg](../assets/diagrams/sequence/seq-position-1.3.4.5-prepare-domain.svg)